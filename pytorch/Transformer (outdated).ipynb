{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aec03969",
   "metadata": {},
   "source": [
    "## Pytorch Implementation of Seq2Seq with RNN (for Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ff4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8ed694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go.' 'Go.' 'Go.' 'Go.' 'Hi.' 'Run!' 'Run!' 'Run!' 'Run!' 'Run.']\n",
      "\n",
      "['Ve.' 'Vete.' 'Vaya.' 'Váyase.' 'Hola.' '¡Corre!' '¡Corran!' '¡Corra!'\n",
      " '¡Corred!' 'Corred.']\n",
      "\n",
      "In total: 128084 pairs of sentences.\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset - note that we need to specify encoding=\"utf-8\" when the language contains non ascii words.\n",
    "sentences_english = []\n",
    "sentences_spanish = []\n",
    "for line in open('../datasets/spa.txt', 'r', encoding = 'utf-8'):\n",
    "    s_english, s_spanish, other = line.rstrip('\\n').split('\\t')\n",
    "    sentences_english.append(s_english)\n",
    "    sentences_spanish.append(s_spanish)   \n",
    "\n",
    "sentences_english = np.array(sentences_english)\n",
    "sentences_spanish = np.array(sentences_spanish)\n",
    "# print to check\n",
    "print(sentences_english[0:10])\n",
    "print()\n",
    "print(sentences_spanish[0:10])\n",
    "print()\n",
    "print('In total: ' + str(len(sentences_spanish)) + ' pairs of sentences.')\n",
    "\n",
    "# The original data is quite large, and may result in high memory usage and long training time. Let's take a sample of 15000\n",
    "idx = np.random.choice(list(range(len(sentences_spanish))), size = 15000, replace = False)\n",
    "sentences_english = sentences_english[idx]\n",
    "sentences_spanish = sentences_spanish[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adcf61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing and vectorization for English-Spanish sentence pairs\n",
    "TEXT_eng = data.Field(sequential=True, init_token = '<start>', eos_token = '<end>', tokenize='spacy', tokenizer_language='en_core_web_sm', lower=True, batch_first=True)\n",
    "TEXT_spa = data.Field(sequential=True, init_token = '<start>', eos_token = '<end>', tokenize='spacy', tokenizer_language='es_core_news_sm', lower=True, batch_first=True)\n",
    "fields = [('English', TEXT_eng), ('Spanish', TEXT_spa)]\n",
    "examples = []\n",
    "for i in range(len(sentences_english)):\n",
    "    examples.append(data.Example.fromlist([sentences_english[i], sentences_spanish[i]], fields))\n",
    "dataset = data.Dataset(examples, fields)\n",
    "TEXT_eng.build_vocab(dataset)\n",
    "TEXT_spa.build_vocab(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6903057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5909\n",
      "[('.', 13004), ('i', 4342), ('the', 3471), ('to', 3303), ('you', 3140), ('tom', 2552), ('a', 2238), ('?', 2028), (\"n't\", 1870), ('is', 1845)]\n",
      "['<unk>', '<pad>', '<start>', '<end>', '.', 'i', 'the', 'to', 'you', 'tom']\n",
      "9682\n",
      "[('.', 12962), ('que', 2752), ('de', 2748), ('no', 2579), ('a', 2563), ('tom', 2420), ('la', 2283), ('¿', 2027), ('?', 2027), ('el', 1826)]\n",
      "['<unk>', '<pad>', '<start>', '<end>', '.', 'que', 'de', 'no', 'a', 'tom']\n"
     ]
    }
   ],
   "source": [
    "# inspect the vocabulary\n",
    "print(len(TEXT_eng.vocab))\n",
    "print(TEXT_eng.vocab.freqs.most_common(10))\n",
    "print(TEXT_eng.vocab.itos[:10])\n",
    "\n",
    "print(len(TEXT_spa.vocab))\n",
    "print(TEXT_spa.vocab.freqs.most_common(10))\n",
    "print(TEXT_spa.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c118b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct train_iterator and valid_iterator\n",
    "# each iterator should constain pairs of Enblish sentences and Spanish sentences\n",
    "train_data, valid_data = dataset.split(split_ratio=0.8)\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((train_data, valid_data), batch_size=128,\n",
    "                                                            sort_key=lambda x: len(x.Spanish),\n",
    "                                                            sort_within_batch=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eae47dca",
   "metadata": {},
   "source": [
    "### Seq2Seq with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12e94c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to define the positional encoding layer\n",
    "# The positional encoding layer is used to add positional information to the input embeddings.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        \"\"\"\n",
    "        :param d_model: the embedding dimension\n",
    "        :param max_len: the maximum length of the sentence\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)  # pe.shape = (max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # position.shape = (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))  # div_term.shape = (d_model/2, )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # pe[:, 0::2].shape = (max_len, d_model/2)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # pe[:, 1::2].shape = (max_len, d_model/2)\n",
    "        pe = pe.unsqueeze(0)  # pe.shape = (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: the input tensor with shape (batch_size, seq_len, d_model)\n",
    "        :return: the tensor after adding positional encoding with shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "# https://pytorch.org/tutorials/beginner/translation_transformer.html#seq2seq-network-using-transformer\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        \"\"\"\n",
    "        :param vocab_size: the size of the vocabulary\n",
    "        :param d_model: the embedding dimension\n",
    "        \"\"\"\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        \"\"\"\n",
    "        :param tokens: the input tensor with shape (batch_size, seq_len)\n",
    "        :return: the tensor after token embedding with shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.d_model)\n",
    "\n",
    "# Second, we need to define the transformer layer\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, src_vocab_size, tgt_vocab_size):\n",
    "        \"\"\"\n",
    "        :param d_model: the embedding dimension\n",
    "        :param nhead: the number of heads in the multiheadattention models\n",
    "        :param num_encoder_layers: the number of sub-encoder-layers in the encoder\n",
    "        :param num_decoder_layers: the number of sub-decoder-layers in the decoder\n",
    "        :param dim_feedforward: the dimension of the feedforward network model\n",
    "        \"\"\"\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, batch_first=True)\n",
    "        self.generator = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, d_model)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
    "        \"\"\"\n",
    "        :param src: the sequence to the encoder (required). with shape (batch_size, seq_len, d_model)\n",
    "        :param tgt: the sequence to the decoder (required). with shape (batch_size, seq_len, d_model)\n",
    "        :param src_mask: the additive mask for the src sequence (optional). with shape (batch_size, seq_len, seq_len)\n",
    "        :param tgt_mask: the additive mask for the tgt sequence (optional). with shape (batch_size, seq_len, seq_len)\n",
    "        :param src_padding_mask: the additive mask for the src sequence (optional). with shape (batch_size, 1, seq_len)\n",
    "        :param tgt_padding_mask: the additive mask for the tgt sequence (optional). with shape (batch_size, 1, seq_len)\n",
    "        :param memory_key_padding_mask: the additive mask for the encoder output (optional). with shape (batch_size, 1, seq_len)\n",
    "        :return: the decoder output tensor with shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "    \n",
    "    # Next, we construct the encoder and decoder layers\n",
    "    # The transformer model is a standard encoder-decoder architecture with multi-head attention.\n",
    "    def encode(self, src):\n",
    "        \"\"\"\n",
    "        :param src: the sequence to the encoder (required). with shape (batch_size, seq_len, d_model)\n",
    "        :return: the encoder output tensor with shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        return self.transformer.encoder(self.positional_encoding(self.src_tok_emb(src)))\n",
    "    \n",
    "    def decode(self, tgt, memory):\n",
    "        \"\"\"\n",
    "        :param tgt: the sequence to the decoder (required). with shape (batch_size, seq_len, d_model)\n",
    "        :param memory: the sequence from the last layer of the encoder (required). with shape (batch_size, seq_len, d_model)\n",
    "        :return: the decoder output tensor with shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbfee55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model parameters and training parameters\n",
    "SRC_VOCAB_SIZE = len(TEXT_eng.vocab)\n",
    "TGT_VOCAB_SIZE = len(TEXT_spa.vocab)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "model = Seq2SeqTransformer(EMB_SIZE, NHEAD, NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, FFN_HID_DIM, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TEXT_spa.vocab.stoi[TEXT_spa.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32c50433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 2.7334858242501605\n",
      "Epoch 0 validation loss: 1.0722072223822277\n",
      "Epoch 1 loss: 0.6545650594412012\n",
      "Epoch 1 validation loss: 0.5788673646748066\n",
      "Epoch 2 loss: 0.23410689228392662\n",
      "Epoch 2 validation loss: 0.4507502367099126\n",
      "Epoch 3 loss: 0.052486242607552955\n",
      "Epoch 3 validation loss: 0.4169566494723161\n",
      "Epoch 4 loss: 0.005499295015977894\n",
      "Epoch 4 validation loss: 0.42874907702207565\n",
      "Epoch 5 loss: 0.0029417891525960666\n",
      "Epoch 5 validation loss: 0.4334271351496379\n",
      "Epoch 6 loss: 0.002171048550232452\n",
      "Epoch 6 validation loss: 0.4338444421688716\n",
      "Epoch 7 loss: 0.0016843575434362951\n",
      "Epoch 7 validation loss: 0.433768833676974\n",
      "Epoch 8 loss: 0.0013666233540750405\n",
      "Epoch 8 validation loss: 0.4354255435367425\n",
      "Epoch 9 loss: 0.0011327030308088883\n",
      "Epoch 9 validation loss: 0.4363349253932635\n"
     ]
    }
   ],
   "source": [
    "# train the model and print out validation loss after each epoch\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_iterator:\n",
    "        src = batch.English\n",
    "        tgt = batch.Spanish\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt, None, None, None, None, None)\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        tgt = tgt.reshape(-1)\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} loss: {epoch_loss/len(train_iterator)}\")\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_iterator:\n",
    "            src = batch.English\n",
    "            tgt = batch.Spanish\n",
    "            output = model(src, tgt, None, None, None, None, None)\n",
    "            output = output.reshape(-1, output.shape[2])\n",
    "            tgt = tgt.reshape(-1)\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} validation loss: {epoch_loss/len(valid_iterator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44e62e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, implement the translate function to translate English to Spanish\n",
    "def translate(sentence, src_field=TEXT_eng, trg_field=TEXT_spa, model=model, max_len=50):\n",
    "    model.eval()\n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.encode(src_tensor)\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = model.decode(trg_tensor, encoder_outputs)\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bd75f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volver',\n",
       " 'cuánto',\n",
       " 'tom',\n",
       " 'mundo',\n",
       " 'hablar',\n",
       " 'ni',\n",
       " 'debes',\n",
       " 'pregunto',\n",
       " 'dicho',\n",
       " 'fuerte',\n",
       " 'volver',\n",
       " 'pasar',\n",
       " 'estado',\n",
       " 'cansado',\n",
       " 'era',\n",
       " 'a',\n",
       " 'recuerdo',\n",
       " 'última',\n",
       " 'escuela',\n",
       " 'otro',\n",
       " 'nosotros',\n",
       " 'jugar',\n",
       " '¿',\n",
       " 'ayudar',\n",
       " 'ningún',\n",
       " 'debe',\n",
       " 'lleva',\n",
       " 'vi',\n",
       " 'noche',\n",
       " 'gracias',\n",
       " 'tener',\n",
       " 'madre',\n",
       " 'policía',\n",
       " 'nosotros',\n",
       " 'debes',\n",
       " 'a',\n",
       " 'recuerdo',\n",
       " 'ni',\n",
       " 'haga',\n",
       " 'visto',\n",
       " 'preguntas',\n",
       " 'favor',\n",
       " 'vive',\n",
       " 'pensar',\n",
       " 'lugar',\n",
       " 'importa',\n",
       " 'un',\n",
       " 'dicho',\n",
       " 'fuerte',\n",
       " 'mucho']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Hello world!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
